---
title: "Review guidelines"
date: 2020-10-26T14:09:13-06:00
---

As a NeuroLibre reviewer, you are responsible for the technical quality of the resources available for our community. Neurolibre welcome submissions along two tracks of neuroscience-related material: (1) tutorials, (2) paper companions. Prior to review, an editor establishes that the submission qualifies in principles, and an administrator has made the resource available for the neurolibre binder, so you can review the material directly on our portal (the link is at the top of the `README.md` file). Now your role is to ensure the submitted materials take full advantage of the notebook format, prior to final publication. Specific criteria for review are listed below.

# Technical review Criteria
Examples of high quality tutorials can be found in the scikit-learn documentation, for example this one on [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html). Examples of high quality article companions can be found as collab links in the article [building blocks of interpretability](https://distill.pub/2018/building-blocks/). Specific areas for review include:
 * Is the text clear and easy to read? In particular, are the sentences free of jargon?
 * Are the figures properly annotated and help understand the flow of the notebook?
 * Are the notebooks of appropriate lengths?
 * Are the notebooks split into logical sections? Could the sections be split or merged between notebooks?
 * For paper companions, is it possible to link each section of the notebook to a figure, or a section of the paper? 
 * Are the code cells short and readable? 
 * Should portions of the code be refactored into a library? 

# Code review
Note that you are not expected to review code libraries shipped with the notebooks. This work is better suited for other publication venues, such as the [Journal of Open Source Software](https://joss.theoj.org/). Minimal feedback is encouraged in the following areas:
 * is the code organized into logical folder structure?
 * is the code documented?
 * are there automated tests implemented?

# Scientific review
Your are not expected to review the scientific soundness of the work. This step is typically handled by traditional peer-review in scientific journals. However, if a work appears to be of obvious unsufficient quality, we encourage you to contact the editors privately and suggest that the submission be withdrawn.

# How to interact with authors
We encourage you to open as many issues as necessary to reach a high quality for the submission. For this purpose, you will use the github issue tracking system on the repository associated with the submission.  Please assign the issues to the lead author of the submission, who will submit a pull request in order to address your comments. Review the pull request and merge it if you think it is appropriate. You can also submit a pull request yourself and ask the author to approve the changes. Please remain courteous and constructive in your feedback, and follow our [code of conduct](COC.md).

When you have completed your review, please leave a comment in the review issue saying so. You can include in your review links to any new issues that you the reviewer believe to be impeding the acceptance of the repository. 

# How to interact with editors and NeuroLibre
You can tag the editors in any of your issues. If you need to communicate privately with an editor, you can use direct messages on the [mattermost brainhack forum](https://mattermost.brainhack.org). You can also post your questions in the ~neurolibre-reviewers channel, if you want the entire NeuroLibre community to help. Just be mindful that authors of the submission have potentially access to this public channel.

# Conflict of interest
The definition of a conflict of Interest in peer review is a circumstance that makes you “unable to make an impartial scientific judgment or evaluation.” (PNAS Conflict of Interest Policy). NeuroLibre is concerned with avoiding any actual conflicts of interest, and being sufficiently transparent that we avoid the appearance of conflicts of interest as well.

As a reviewer, conflict of interests are your present or previous association with any authors of a submission: recent (past four years) collaborators in funded research or work that is published; and lifetime for the family members, business partners, and thesis student/advisor or mentor. In addition, your recent (past year) association with the same organization of a submitter is a COI, for example, being employed at the same institution.

If you have a conflict of interest with a submission, you should disclose the specific reason to the submissions’ editor. This may lead to you not being able to review the submission, but some conflicts may be recorded and then waived, and if you think you are able to make an impartial assessment of the work, you should request that the conflict be waived. For example, if you and a submitter were two of 2000 authors of a high energy physics paper but did not actually collaborate. Or if you and a submitter worked together 6 years ago, but due to delays in the publishing industry, a paper from that collaboration with both of you as authors was published 2 year ago. Or if you and a submitter are both employed by the same very large organization but in different units without any knowledge of each other.

Declaring actual, perceived, and potential conflicts of interest is required under professional ethics. If in doubt: ask the editors.
# Attribution
Some material in this section was adapted from the "Journal of Open Source Software" [reviewing guidelines](https://github.com/openjournals/joss/blob/master/docs/reviewer_guidelines.md), released under an MIT license.

